{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome(executable_path=\"C:/Users/Owner/Downloads/chromedriver.exe\", options=option)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.niche.com/places-to-live/search/best-places-to-live/s/texas/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(2)\n",
    "search_textinput=driver.find_element(By.XPATH, \"//input[@placeholder = 'Texas']\")\n",
    "search_textinput.send_keys('Dallas-Fort Worth Area')\n",
    "search_textinput.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identifying Suburbs Checkbox\n",
    "checkbox_input=driver.find_element(By.XPATH,\"//*[@id='maincontent']/div/div/div[1]/aside/div[3]/div/div/div[3]/label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clicking on Suburbs checkbox to activate it and narrow down number of neighborhoods results to scrape\n",
    "time.sleep(2)\n",
    "checkbox_input.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking current url\n",
    "print(driver.current_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Identify Number of Pages by looking at tag of dropdown options at the bottom of the page\n",
    "time.sleep(2)\n",
    "no_pages_detect= driver.find_elements_by_tag_name('option')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(no_pages_detect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfw_dict={'neighborhood':[],'neighborhood_description':[],'niche_grade':[],'population':[],'median_home_value':[],'median_rent':[],'median_household_income':[],'niche_page':[]\n",
    "          ,'public_school_grade_list':[], 'crime_grade_list':[], 'housing_grade_list':[],'nightlife_grade':[]\n",
    "          ,'good_for_families_grade':[], 'diversity_grade':[],'jobs_grade':[] , 'weather_grade':[],'cost_of_living_grade':[]\n",
    "          , 'health_grade':[],'outdoor_activities_grade':[],'commute_grade':[]}\n",
    "\n",
    "for page in range(1,len(no_pages_detect)+1): #Ideally this should be 'for page in range (1, len(no_pages_detect))'. However, due to recaptcha limitidation, we are breaking down the extrations into batches by defining the range manually. Make sure the driver is on the page# that is listed as the beginning of the range.\n",
    "    if page < len(no_pages_detect): # The loops below are applicable to all but the last page of results as we do not know how many results are posted in the last page.\n",
    "        for i in range (1,30):\n",
    "            if i in [7,8,20,21]: #xpath numbers are not continuous. We are ignoring these xpath numbers as they are absent in the website. Inclduing them will result in errors\n",
    "                continue\n",
    "            \n",
    "            city_page=driver.find_element_by_xpath(\"//*[@id='maincontent']/div/div/section/div[2]/ol/li[{}]/div/div/a\".format(i))\n",
    "            \n",
    "            #scrolling to city prior to selecting\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", city_page)\n",
    "            \n",
    "            time.sleep(.2) #wating .2 second post scrolling to click\n",
    "            \n",
    "            #Click on Neighborhood name to navigate to Neighborhood Details Page\n",
    "            driver.execute_script(\"arguments[0].click();\", city_page)\n",
    "            \n",
    "            #Prociding 1.5 seconds for page to Load\n",
    "            time.sleep(1.5)\n",
    "            \n",
    "            #Determining neighborhood for which we will be scraping data\n",
    "            neighborhood=driver.find_element_by_xpath(\"//*[@id='header']/div/div[2]/div[1]/h1\")\n",
    "            neighborhood_name_main=(neighborhood.text)\n",
    "\n",
    "            print(\"Entering {}'s Detail's Page\".format(neighborhood_name_main))\n",
    "\n",
    "\n",
    "            #Clicking on 'View Full Report' option to expand report prior to extraction. All data points will not be scraped if this report is not explanded\n",
    "            expand_report=driver.find_element_by_xpath('//*[@id=\"report-card\"]/div/div[2]/a')\n",
    "            \n",
    "            time.sleep(.1) # waiting for page to load\n",
    "            \n",
    "            #scrolling to expand report prior to clicking\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView();\", expand_report)\n",
    "            \n",
    "            time.sleep(.05)# wait before clicing\n",
    "            \n",
    "            driver.execute_script(\"arguments[0].click();\", expand_report)\n",
    "\n",
    "            #Extracting Neighborhood Details from details page:\n",
    "            for i in list(dfw_dict.keys()):\n",
    "                \n",
    "                #We will now assign values to the dfw_dict dictionary based on position of the keys(columns) in the dictionary\n",
    "                \n",
    "                if list(dfw_dict.keys()).index(i)==0: #Neighboord is the first key in the dfw_dictionary\n",
    "                    try:\n",
    "                        neighborhood=driver.find_element_by_xpath(\"//*[@id='header']/div/div[2]/div[1]/h1\")\n",
    "                        dfw_dict[i].append(neighborhood.text)\n",
    "                        #print(\"Neighborhood name extraction complete!\") # unmute only while debudding in case of errors\n",
    "                    except:\n",
    "                        dfw_dict[i].append(\"NA\")\n",
    "                        \n",
    "                        \n",
    "                    \n",
    "                elif list(dfw_dict.keys()).index(i)==1: \n",
    "                    try:\n",
    "                        neighborhood_description=driver.find_element_by_xpath('//*[@id=\"header\"]/div/div[2]/div[1]/ul[1]/li[2]')\n",
    "                        dfw_dict[i].append(neighborhood_description.text)\n",
    "                        #print(\"Neighborhood description extraction complete!\") # unmute only while debudding in case of errors\n",
    "                    except:\n",
    "                        dfw_dict[i].append(\"NA\")\n",
    "                        \n",
    "                elif list(dfw_dict.keys()).index(i)==2:\n",
    "                    try:\n",
    "                        niche_grade=driver.find_element_by_xpath('//*[@id=\"report-card\"]/div/div[1]/div/div[1]/div/div/div/div[1]/div')\n",
    "                        dfw_dict[i].append(niche_grade.text)\n",
    "                    except:\n",
    "                        dfw_dict[i].append(\"NA\")\n",
    "                        #print(\"Niche grade extraction complete!\") # unmute only while debudding in case of errors\n",
    "                    \n",
    "\n",
    "                elif list(dfw_dict.keys()).index(i)==3:\n",
    "                    try:\n",
    "                        population=driver.find_element_by_xpath(\"//*[@id='about']/div[2]/div[1]/div/div/div[2]/div[2]/span\")\n",
    "                        #scrolling to population part of the page\n",
    "                        driver.execute_script(\"arguments[0].scrollIntoView();\", expand_report)\n",
    "                        time.sleep(.2)\n",
    "                        dfw_dict[i].append(population.text)\n",
    "                        #print(\"Population extraction complete!\") # unmute only while debudding in case of errors\n",
    "                    except:\n",
    "                        dfw_dict[i].append(\"0\")\n",
    "\n",
    "\n",
    "                elif list(dfw_dict.keys()).index(i) ==4:\n",
    "                    try:\n",
    "                        home_value=driver.find_element_by_xpath('//*[@id=\"real-estate\"]/div[2]/div[1]/div/div/div[1]/div[2]/span')\n",
    "                        dfw_dict[i].append(home_value.text)\n",
    "                        #print(\"Median home value extraction complete!\") # unmute only while debudding in case of errors\n",
    "                    except:\n",
    "                        dfw_dict[i].append(\"0\")\n",
    "                        #print(\"Median home value not available!\") # unmute only while debudding in case of errors\n",
    "\n",
    "                elif list(dfw_dict.keys()).index(i) ==5:\n",
    "                    try:\n",
    "                        median_rent=driver.find_element_by_xpath('//*[@id=\"real-estate\"]/div[2]/div[1]/div/div/div[2]/div[2]/span')\n",
    "                        dfw_dict[i].append(median_rent.text)\n",
    "                        #print(\"Median rent extraction complete!\") # unmute only while debudding in case of errors\n",
    "                    except:\n",
    "                        dfw_dict[i].append(\"0\")\n",
    "                        #print(\"Median rent not available!\") # unmute only while debudding in case of errors\n",
    "                        \n",
    "\n",
    "                elif list(dfw_dict.keys()).index(i) ==6:\n",
    "                    try:\n",
    "                        median_household_income=driver.find_element_by_xpath('//*[@id=\"working-in\"]/div[2]/div[2]/div/div/div[1]/div[2]/span')\n",
    "                        dfw_dict[i].append(median_household_income.text)\n",
    "                        #print(\"Median household income extraction complete!\") # unmute only while debudding in case of errors\n",
    "                    except:\n",
    "                        dfw_dict[i].append(\"0\")\n",
    "                        #print(\"Median household income not available!\") # unmute only while debudding in case of errors\n",
    "                \n",
    "                elif list(dfw_dict.keys()).index(i) ==7:\n",
    "                    dfw_dict[i].append(page)\n",
    "                    #print(\"Median household income extraction complete!\") # unmute only while debudding in case of errors\n",
    "\n",
    "                else:\n",
    "                    try:\n",
    "                        n=list(dfw_dict.keys()).index(i)-7\n",
    "                        element=driver.find_element_by_xpath(\"//*[@id='report-card']/div/div[1]/div/div[2]/ol/li[{}]/div/div[2]\".format(n))\n",
    "                        dfw_dict[i].append(element.text)\n",
    "                        n=n+1\n",
    "                        #print(\"Other metrics extraction complete!\") # unmute only while debudding in case of errors\n",
    "                    except:\n",
    "                        dfw_dict[i].append(\"NA\")\n",
    "                        #print(\"Other metrics not available!\") # unmute only while debudding in case of errors\n",
    "\n",
    "                    \n",
    "            print(\"All data extraction complete\")\n",
    "            \n",
    "            #scrolling back to top of page prior to clicking back\n",
    "            driver.execute_script(\"window.scrollTo(0,0)\")\n",
    "            time.sleep(1)\n",
    "            #navigating back to results page in order to select next city for scraping details\n",
    "            driver.execute_script(\"window.history.go(-1)\")\n",
    "            print(\"Returning to Main Neighborhood Page\")\n",
    "            time.sleep(2) #holding a 2 second wait to allow results page ample time to load. Increase this time if code is executing faster than pages are loading\n",
    "            \n",
    "        #scrolling to bottom of the page prior to clicking next page button\n",
    "        driver.execute_script(\"window.scrollTo(0,document.body.scrollHeight)\")\n",
    "        time.sleep(.5) #waiting half a second prior to clicking next\n",
    "        #At this stage, scraping of data in the current results page has been compelte.Code below will take us to the next page of results   \n",
    "        next_page=driver.find_element(By.XPATH, \"//li[@class = 'pagination__next']\")\n",
    "        driver.execute_script(\"arguments[0].click();\", next_page)\n",
    "        time.sleep(3) #holding a 3 second wait to allow next page of results ample time to load. Increase this time if code is executing faster than pages are loading\n",
    "\n",
    "            \n",
    "      \n",
    "    \n",
    "    \n",
    "    #scraping results from last Page of results\n",
    "    else:\n",
    "        #Determining number of results in the last page of results\n",
    "        no_neighbords_in_last_results_page=[]\n",
    "        neighborhoods = driver.find_elements_by_css_selector('h2[class=\"search-result__title\"]')\n",
    "        \n",
    "        for i in range (1,len(neighborhoods)+3):\n",
    "            if i in [7,8,20,21]: #skipping these numbers as they do't exists in xpath\n",
    "                continue\n",
    "            city_page=driver.find_element_by_xpath(\"//*[@id='maincontent']/div/div/section/div[2]/ol/li[{}]/div/div/a\".format(i))\n",
    "\n",
    "            #Click on City name to go to Details Page\n",
    "            driver.execute_script(\"arguments[0].click();\", city_page)\n",
    "\n",
    "            neighborhood=driver.find_element_by_xpath(\"//*[@id='header']/div/div[2]/div[1]/h1\")\n",
    "            neighborhood_name_main=(neighborhood.text)\n",
    "\n",
    "            print(\"Entering {}'s Detail's Page\".format(neighborhood_name_main))\n",
    "\n",
    "\n",
    "            #Clicking on 'View Full Report' option to expand report prior to extraction\n",
    "            expand_report=driver.find_element_by_xpath('//*[@id=\"report-card\"]/div/div[2]/a')\n",
    "            driver.execute_script(\"arguments[0].click();\", expand_report)\n",
    "\n",
    "            #Extracting Neighborhood Details from details page\n",
    "            for i in list(dfw_dict.keys()):\n",
    "                if list(dfw_dict.keys()).index(i)==0:\n",
    "                    try:\n",
    "                        neighborhood=driver.find_element_by_xpath(\"//*[@id='header']/div/div[2]/div[1]/h1\")\n",
    "                        dfw_dict[i].append(neighborhood.text)\n",
    "                        #print(\"Neighborhood name extraction complete!\")\n",
    "                    except:\n",
    "                        dfw_dict[i].append(\"NA\")\n",
    "                        \n",
    "                        \n",
    "                    \n",
    "                elif list(dfw_dict.keys()).index(i)==1:\n",
    "                    try:\n",
    "                        neighborhood_description=driver.find_element_by_xpath('//*[@id=\"header\"]/div/div[2]/div[1]/ul[1]/li[2]')\n",
    "                        dfw_dict[i].append(neighborhood_description.text)\n",
    "                        #print(\"Neighborhood name extraction complete!\")\n",
    "                    except:\n",
    "                        dfw_dict[i].append(\"NA\")\n",
    "                        \n",
    "                elif list(dfw_dict.keys()).index(i)==2:\n",
    "                    try:\n",
    "                        niche_grade=driver.find_element_by_xpath('//*[@id=\"report-card\"]/div/div[1]/div/div[1]/div/div/div/div[1]/div')\n",
    "                        dfw_dict[i].append(niche_grade.text)\n",
    "                    except:\n",
    "                        dfw_dict[i].append(\"NA\")\n",
    "                    \n",
    "\n",
    "                elif list(dfw_dict.keys()).index(i)==3:\n",
    "                    try:\n",
    "                        population=driver.find_element_by_xpath(\"//*[@id='about']/div[2]/div[1]/div/div/div[2]/div[2]/span\")\n",
    "                        dfw_dict[i].append(population.text)\n",
    "                        #print(\"Population extraction complete!\")\n",
    "                    except:\n",
    "                        dfw_dict[i].append(\"0\")\n",
    "\n",
    "\n",
    "                elif list(dfw_dict.keys()).index(i) ==4:\n",
    "                    try:\n",
    "                        home_value=driver.find_element_by_xpath('//*[@id=\"real-estate\"]/div[2]/div[1]/div/div/div[1]/div[2]/span')\n",
    "                        dfw_dict[i].append(home_value.text)\n",
    "                        #print(\"Median home value extraction complete!\")\n",
    "                    except:\n",
    "                        dfw_dict[i].append(\"0\")\n",
    "\n",
    "                elif list(dfw_dict.keys()).index(i) ==5:\n",
    "                    try:\n",
    "                        median_rent=driver.find_element_by_xpath('//*[@id=\"real-estate\"]/div[2]/div[1]/div/div/div[2]/div[2]/span')\n",
    "                        dfw_dict[i].append(median_rent.text)\n",
    "                    except:\n",
    "                        dfw_dict[i].append(\"0\")\n",
    "                    #print(\"Median rent extraction complete!\")\n",
    "\n",
    "                elif list(dfw_dict.keys()).index(i) ==6:\n",
    "                    try:\n",
    "                        median_household_income=driver.find_element_by_xpath('//*[@id=\"working-in\"]/div[2]/div[2]/div/div/div[1]/div[2]/span')\n",
    "                        dfw_dict[i].append(median_household_income.text)\n",
    "                        #print(\"Median household income extraction complete!\")\n",
    "                    except:\n",
    "                        dfw_dict[i].append(\"0\")\n",
    "                \n",
    "                elif list(dfw_dict.keys()).index(i) ==7:\n",
    "                    dfw_dict[i].append(page)\n",
    "\n",
    "                else:\n",
    "                    try:\n",
    "                        n=list(dfw_dict.keys()).index(i)-7\n",
    "                        element=driver.find_element_by_xpath(\"//*[@id='report-card']/div/div[1]/div/div[2]/ol/li[{}]/div/div[2]\".format(n))\n",
    "                        dfw_dict[i].append(element.text)\n",
    "                        n=n+1\n",
    "                        #time.sleep(1) \n",
    "                    except:\n",
    "                        dfw_dict[i].append(\"NA\")\n",
    "                        \n",
    "            print(\"All data extraction complete\")\n",
    "            driver.execute_script(\"window.history.go(-1)\")\n",
    "            print(\"Returning to Main Neighborhood Page\")\n",
    "            time.sleep(3)\n",
    "            \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df=dfw_data_1.append(dfw_data_2_3, ignore_index=True)\n",
    "df=df.append(dfw_data_4_5, ignore_index=True)\n",
    "df=df.append(dfw_data_6, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('dfw_data.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
